{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ed35640",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input \n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Flatten, Dropout, Activation, Input, Conv2D, MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras import Sequential\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfa9e83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001 #diminui o valor do learning rate pois estamos usando Adam como otimizador"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449be637",
   "metadata": {},
   "source": [
    "## Treinamento Rede Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa5ec7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(pasta):\n",
    "    exts = ['.PNG','.JPG','.JPEG','.TIFF','.GIF','.BMP']\n",
    "    tot_images = 0\n",
    "    for sf in [name for name in os.listdir(pasta) if os.path.isdir(os.path.join(pasta, name))]:\n",
    "        subdir = os.path.join(pasta,sf)\n",
    "        tot_images = tot_images + len([name for name in os.listdir(subdir) if os.path.splitext(name)[1].upper() in exts])\n",
    "    return tot_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee94bab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNÇÃO PARA LER O NOME DAS CLASSES\n",
    "def get_labels(pasta):\n",
    "    return [name for name in os.listdir(pasta) if os.path.isdir(os.path.join(pasta, name))];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b6dee83",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50;\n",
    "BATCH_SIZE = 16; #serão gerados batches de 16 imagens (a rede vê 16 imagens de cada vez durante o treino). Esse número é para facilitar o processamento conforme a memória do computador durante o treino, colocamos 16 não travar\n",
    "IMG_SIZE = (299,299,3);\n",
    "optimizer_name = 'SGD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a21a2a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFolder = 'C:\\\\Users\\\\LDT\\\\Desktop\\\\mestrado-unifesp\\\\db\\\\train_v2'\n",
    "valFolder = 'C:\\\\Users\\\\LDT\\\\Desktop\\\\mestrado-unifesp\\\\db\\\\val_v2'\n",
    "labels = get_labels(trainFolder)\n",
    "labels = np.array(labels);\n",
    "\n",
    "# Organiza os labels em matriz e salva, para posterior uso em classificação\n",
    "lb = LabelBinarizer();\n",
    "labels = lb.fit_transform(labels);\n",
    "f = open('C:\\\\Users\\\\LDT\\\\Desktop\\\\mestrado-unifesp\\\\budioes_inception_v2_' + optimizer_name + '_' + str(learning_rate) + \".pickle\", \"wb\")\n",
    "f.write(pickle.dumps(lb));\n",
    "f.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de21a0c9",
   "metadata": {},
   "source": [
    "ImageDataGenerator = Carrega aos poucos as imagens em memória para fazer a leitura (para não estourar a memória)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07f4c6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ImageDataGenerator = objeto para buscar as imagens em uma pasta\n",
    "#Treino\n",
    "#Quando carregar as imagens, será aplicada a função \"preprocess_input\" pré definida pela rede inception\n",
    "#O \"preprocess_input\" modifica os valores da imagem para facilitar o processamento.\n",
    "augTrain = ImageDataGenerator(preprocessing_function=preprocess_input, rotation_range=20, width_shift_range = 0.1, height_shift_range = 0.1, \n",
    "                              shear_range = 0.15, zoom_range = [1.0, 1.25], horizontal_flip=True, \n",
    "                              fill_mode=\"nearest\");\n",
    "#Validação\n",
    "augVal = ImageDataGenerator(preprocessing_function=preprocess_input);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69efda31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaração da rede INCEPTION V3\n",
    "# Pega só as camadas de convolução e retreina as de classificação\n",
    "\n",
    "baseModel = InceptionV3(include_top=False, weights=\"imagenet\", input_shape=(299,299,3), pooling='avg') \n",
    "#sempre usa 3 como parametro do input pois corresponde ao tamanho do RGB da imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d33531c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Como vamos usar imagenet, não faz sentido treinar a rede novamente pois já vamos usar o modelo treinado\n",
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2158b2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Include_Top feito \"Na mão\":\n",
    "\n",
    "#É preciso criar novas camadas (headModel) pra zerar os pesos da VGG\n",
    "headModel = baseModel.output\n",
    "headModel = Dense(len(lb.classes_), activation=\"softmax\", name='predictions')(headModel)\n",
    "#Junta tudo num modelo só\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8da40e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7be6649d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if optimizer_name == 'Adam':\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "if optimizer_name == 'SGD':\n",
    "    optimizer = SGD(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd8a8d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#No nosso modelo, o callback irá salvar o melhor modelo entre as épocas (epochs) - função Model Checkpoint\n",
    "callbacks = [\n",
    "    #ReduceLROnPlateau(monitor = 'val_acc',factor=0.85, patience=10, min_lr=0.000001, verbose=1),\n",
    "    ModelCheckpoint('C:\\\\Users\\\\LDT\\\\Desktop\\\\mestrado-unifesp\\\\exemplos\\\\modelo_budioes_inception_v2_' + optimizer_name + '_' + str(learning_rate) + \n",
    "                    '-ckpnt.model', save_best_only=True, monitor='val_accuracy', mode='max', verbose = 1)\n",
    "]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83ce0695",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reservando espaço de memória para a rede funcionar\n",
    "#Ao final de cada época, será rodado o comando \"callbacks\"\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02c88584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 594 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "#Função para buscar imagens\n",
    "#TREINO\n",
    "trainGen = augTrain.flow_from_directory(\n",
    "    trainFolder, #caminho da imagem\n",
    "    class_mode=\"categorical\", #o nome da pasta onde está a imagem será o nome da classe\n",
    "    target_size=(IMG_SIZE[0], IMG_SIZE[1]), #tamanho da imagem a ser redimensionada\n",
    "    color_mode=\"rgb\", #a imagem terá 3 canais RGB\n",
    "    shuffle=True, #vai embaralhar as imagens enquanto faz a leitura\n",
    "    batch_size=BATCH_SIZE); #de quantas em quantas imagens será feita a leitura (tamanho do BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b41b1505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 122 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "#Função para buscar imagens\n",
    "#VALIDAÇÃO\n",
    "valGen = augVal.flow_from_directory(\n",
    "    valFolder,\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(IMG_SIZE[0], IMG_SIZE[1]),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4702faba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 149, 149, 32) 96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 149, 149, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 147, 147, 32) 9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 147, 147, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 147, 147, 64) 18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 147, 147, 64) 192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 73, 73, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 73, 73, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 73, 73, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 71, 71, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 71, 71, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 71, 71, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 35, 35, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 35, 35, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 35, 35, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 35, 35, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 35, 35, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 35, 35, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 35, 35, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 35, 35, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 35, 35, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 35, 35, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 35, 35, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 35, 35, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 35, 35, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 35, 35, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 35, 35, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 35, 35, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 35, 35, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 35, 35, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 35, 35, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 35, 35, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 35, 35, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 35, 35, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 35, 35, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 35, 35, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 35, 35, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 35, 35, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 35, 35, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 35, 35, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 35, 35, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 35, 35, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 35, 35, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 35, 35, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 35, 35, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 35, 35, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 35, 35, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 35, 35, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 35, 35, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 35, 35, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 35, 35, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 35, 35, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 35, 35, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 35, 35, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 35, 35, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 35, 35, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 35, 35, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 35, 35, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 17, 17, 96)   82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 17, 17, 384)  1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 17, 17, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 17, 17, 384)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 17, 17, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 17, 17, 128)  384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 17, 17, 128)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 17, 17, 128)  114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 17, 17, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 17, 17, 128)  384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 17, 17, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 17, 17, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 17, 17, 128)  114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 17, 17, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 17, 17, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 17, 17, 192)  172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 17, 17, 192)  172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 17, 17, 192)  576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 17, 17, 192)  576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 17, 17, 192)  576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 17, 17, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 17, 17, 192)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 17, 17, 192)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 17, 17, 192)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 17, 17, 160)  480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 17, 17, 160)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 17, 17, 160)  179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 17, 17, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 17, 17, 160)  480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 17, 17, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 17, 17, 160)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 17, 17, 160)  179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 17, 17, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 17, 17, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 17, 17, 192)  215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 17, 17, 192)  215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 17, 17, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 17, 17, 192)  576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 17, 17, 192)  576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 17, 17, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 17, 17, 192)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 17, 17, 192)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 17, 17, 160)  480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 17, 17, 160)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 17, 17, 160)  179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 17, 17, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 17, 17, 160)  480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 17, 17, 160)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 17, 17, 160)  179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 17, 17, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 17, 17, 192)  215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 17, 17, 192)  215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 17, 17, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 17, 17, 192)  576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 17, 17, 192)  576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 17, 17, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 17, 17, 192)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 17, 17, 192)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 17, 17, 192)  258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 17, 17, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 17, 17, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 17, 17, 192)  258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 17, 17, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 17, 17, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 17, 17, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 17, 17, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 17, 17, 192)  576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 17, 17, 192)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 17, 17, 192)  258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 17, 17, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 8, 8, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 8, 8, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 8, 8, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 8, 8, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 8, 8, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 8, 8, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 8, 8, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 8, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 8, 8, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 8, 8, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 8, 8, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 8, 8, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 8, 8, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 8, 8, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 8, 8, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 8, 8, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 8, 8, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 8, 8, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8, 8, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 8, 8, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 8, 8, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 8, 8, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 8, 8, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 8, 8, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 8, 8, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 8, 8, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 8, 8, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 8, 8, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 8, 8, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 8, 8, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 8, 8, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 8, 8, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 8, 8, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 8, 8, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 8, 8, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 8, 8, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 3)            6147        global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 21,808,931\n",
      "Trainable params: 6,147\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7efb4850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "37/37 [==============================] - 27s 480ms/step - loss: 1.1510 - accuracy: 0.3183 - val_loss: 1.1073 - val_accuracy: 0.3750\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.37500, saving model to C:\\Users\\LDT\\Desktop\\mestrado-unifesp\\exemplos\\modelo_budioes_inception_v2_SGD_0.001-ckpnt.model\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\LDT\\Desktop\\mestrado-unifesp\\exemplos\\modelo_budioes_inception_v2_SGD_0.001-ckpnt.model\\assets\n",
      "Epoch 2/50\n",
      "37/37 [==============================] - 14s 375ms/step - loss: 1.0661 - accuracy: 0.4172 - val_loss: 1.0259 - val_accuracy: 0.4821\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.37500 to 0.48214, saving model to C:\\Users\\LDT\\Desktop\\mestrado-unifesp\\exemplos\\modelo_budioes_inception_v2_SGD_0.001-ckpnt.model\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\LDT\\Desktop\\mestrado-unifesp\\exemplos\\modelo_budioes_inception_v2_SGD_0.001-ckpnt.model\\assets\n",
      "Epoch 3/50\n",
      "37/37 [==============================] - 14s 365ms/step - loss: 0.9932 - accuracy: 0.5138 - val_loss: 0.9969 - val_accuracy: 0.5089\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.48214 to 0.50893, saving model to C:\\Users\\LDT\\Desktop\\mestrado-unifesp\\exemplos\\modelo_budioes_inception_v2_SGD_0.001-ckpnt.model\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\LDT\\Desktop\\mestrado-unifesp\\exemplos\\modelo_budioes_inception_v2_SGD_0.001-ckpnt.model\\assets\n",
      "Epoch 4/50\n",
      "37/37 [==============================] - 15s 383ms/step - loss: 0.9451 - accuracy: 0.5588 - val_loss: 0.9569 - val_accuracy: 0.6071\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.50893 to 0.60714, saving model to C:\\Users\\LDT\\Desktop\\mestrado-unifesp\\exemplos\\modelo_budioes_inception_v2_SGD_0.001-ckpnt.model\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\LDT\\Desktop\\mestrado-unifesp\\exemplos\\modelo_budioes_inception_v2_SGD_0.001-ckpnt.model\\assets\n",
      "Epoch 5/50\n",
      "37/37 [==============================] - 14s 376ms/step - loss: 0.8813 - accuracy: 0.6436 - val_loss: 0.9148 - val_accuracy: 0.6250\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.60714 to 0.62500, saving model to C:\\Users\\LDT\\Desktop\\mestrado-unifesp\\exemplos\\modelo_budioes_inception_v2_SGD_0.001-ckpnt.model\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\LDT\\Desktop\\mestrado-unifesp\\exemplos\\modelo_budioes_inception_v2_SGD_0.001-ckpnt.model\\assets\n",
      "Epoch 6/50\n",
      "37/37 [==============================] - 14s 374ms/step - loss: 0.8539 - accuracy: 0.6696 - val_loss: 0.8733 - val_accuracy: 0.6696\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.62500 to 0.66964, saving model to C:\\Users\\LDT\\Desktop\\mestrado-unifesp\\exemplos\\modelo_budioes_inception_v2_SGD_0.001-ckpnt.model\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\LDT\\Desktop\\mestrado-unifesp\\exemplos\\modelo_budioes_inception_v2_SGD_0.001-ckpnt.model\\assets\n",
      "Epoch 7/50\n",
      "37/37 [==============================] - 14s 374ms/step - loss: 0.8046 - accuracy: 0.7145 - val_loss: 0.8534 - val_accuracy: 0.6786\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.66964 to 0.67857, saving model to C:\\Users\\LDT\\Desktop\\mestrado-unifesp\\exemplos\\modelo_budioes_inception_v2_SGD_0.001-ckpnt.model\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\LDT\\Desktop\\mestrado-unifesp\\exemplos\\modelo_budioes_inception_v2_SGD_0.001-ckpnt.model\\assets\n",
      "Epoch 8/50\n",
      "37/37 [==============================] - 14s 378ms/step - loss: 0.7810 - accuracy: 0.7145 - val_loss: 0.7883 - val_accuracy: 0.7679\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.67857 to 0.76786, saving model to C:\\Users\\LDT\\Desktop\\mestrado-unifesp\\exemplos\\modelo_budioes_inception_v2_SGD_0.001-ckpnt.model\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\LDT\\Desktop\\mestrado-unifesp\\exemplos\\modelo_budioes_inception_v2_SGD_0.001-ckpnt.model\\assets\n",
      "Epoch 9/50\n",
      "37/37 [==============================] - 14s 369ms/step - loss: 0.7346 - accuracy: 0.7578 - val_loss: 0.7729 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.76786 to 0.78571, saving model to C:\\Users\\LDT\\Desktop\\mestrado-unifesp\\exemplos\\modelo_budioes_inception_v2_SGD_0.001-ckpnt.model\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\LDT\\Desktop\\mestrado-unifesp\\exemplos\\modelo_budioes_inception_v2_SGD_0.001-ckpnt.model\\assets\n",
      "Epoch 10/50\n",
      "37/37 [==============================] - 15s 387ms/step - loss: 0.7357 - accuracy: 0.7561 - val_loss: 0.7735 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.78571\n",
      "Epoch 11/50\n",
      "37/37 [==============================] - 15s 405ms/step - loss: 0.7072 - accuracy: 0.7716 - val_loss: 0.7762 - val_accuracy: 0.7500\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.78571\n",
      "Epoch 12/50\n",
      "37/37 [==============================] - 16s 442ms/step - loss: 0.6743 - accuracy: 0.8010 - val_loss: 0.7306 - val_accuracy: 0.8036\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.78571 to 0.80357, saving model to C:\\Users\\LDT\\Desktop\\mestrado-unifesp\\exemplos\\modelo_budioes_inception_v2_SGD_0.001-ckpnt.model\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\LDT\\Desktop\\mestrado-unifesp\\exemplos\\modelo_budioes_inception_v2_SGD_0.001-ckpnt.model\\assets\n",
      "Epoch 13/50\n",
      "37/37 [==============================] - 15s 403ms/step - loss: 0.6496 - accuracy: 0.8131 - val_loss: 0.7381 - val_accuracy: 0.7857\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.80357\n",
      "Epoch 14/50\n",
      "37/37 [==============================] - 15s 392ms/step - loss: 0.6427 - accuracy: 0.7941 - val_loss: 0.6870 - val_accuracy: 0.8482\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.80357 to 0.84821, saving model to C:\\Users\\LDT\\Desktop\\mestrado-unifesp\\exemplos\\modelo_budioes_inception_v2_SGD_0.001-ckpnt.model\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\LDT\\Desktop\\mestrado-unifesp\\exemplos\\modelo_budioes_inception_v2_SGD_0.001-ckpnt.model\\assets\n",
      "Epoch 15/50\n",
      "37/37 [==============================] - 15s 399ms/step - loss: 0.6162 - accuracy: 0.8183 - val_loss: 0.7170 - val_accuracy: 0.7589\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.84821\n",
      "Epoch 16/50\n",
      "37/37 [==============================] - 16s 427ms/step - loss: 0.6083 - accuracy: 0.8149 - val_loss: 0.6766 - val_accuracy: 0.8304\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.84821\n",
      "Epoch 17/50\n",
      "37/37 [==============================] - 15s 405ms/step - loss: 0.5993 - accuracy: 0.8356 - val_loss: 0.6676 - val_accuracy: 0.8214\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.84821\n",
      "Epoch 18/50\n",
      "37/37 [==============================] - 14s 386ms/step - loss: 0.5857 - accuracy: 0.8391 - val_loss: 0.6336 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.84821 to 0.85714, saving model to C:\\Users\\LDT\\Desktop\\mestrado-unifesp\\exemplos\\modelo_budioes_inception_v2_SGD_0.001-ckpnt.model\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\LDT\\Desktop\\mestrado-unifesp\\exemplos\\modelo_budioes_inception_v2_SGD_0.001-ckpnt.model\\assets\n",
      "Epoch 19/50\n",
      "37/37 [==============================] - 15s 385ms/step - loss: 0.5661 - accuracy: 0.8322 - val_loss: 0.6426 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.85714\n",
      "Epoch 20/50\n",
      "37/37 [==============================] - 14s 386ms/step - loss: 0.5578 - accuracy: 0.8374 - val_loss: 0.6443 - val_accuracy: 0.8482\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.85714\n",
      "Epoch 21/50\n",
      "37/37 [==============================] - 14s 385ms/step - loss: 0.5575 - accuracy: 0.8495 - val_loss: 0.6059 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.85714 to 0.87500, saving model to C:\\Users\\LDT\\Desktop\\mestrado-unifesp\\exemplos\\modelo_budioes_inception_v2_SGD_0.001-ckpnt.model\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\LDT\\Desktop\\mestrado-unifesp\\exemplos\\modelo_budioes_inception_v2_SGD_0.001-ckpnt.model\\assets\n",
      "Epoch 22/50\n",
      "37/37 [==============================] - 14s 381ms/step - loss: 0.5491 - accuracy: 0.8374 - val_loss: 0.6215 - val_accuracy: 0.8661\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.87500\n",
      "Epoch 23/50\n",
      "37/37 [==============================] - 14s 384ms/step - loss: 0.5306 - accuracy: 0.8408 - val_loss: 0.6173 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.87500\n",
      "Epoch 24/50\n",
      "37/37 [==============================] - 15s 411ms/step - loss: 0.5157 - accuracy: 0.8408 - val_loss: 0.6108 - val_accuracy: 0.8393\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.87500\n",
      "Epoch 25/50\n",
      "37/37 [==============================] - 16s 438ms/step - loss: 0.5084 - accuracy: 0.8512 - val_loss: 0.5945 - val_accuracy: 0.8661\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.87500\n",
      "Epoch 26/50\n",
      "37/37 [==============================] - 14s 381ms/step - loss: 0.4931 - accuracy: 0.8737 - val_loss: 0.5955 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.87500\n",
      "Epoch 27/50\n",
      "37/37 [==============================] - 15s 400ms/step - loss: 0.4831 - accuracy: 0.8651 - val_loss: 0.5569 - val_accuracy: 0.8839\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.87500 to 0.88393, saving model to C:\\Users\\LDT\\Desktop\\mestrado-unifesp\\exemplos\\modelo_budioes_inception_v2_SGD_0.001-ckpnt.model\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\LDT\\Desktop\\mestrado-unifesp\\exemplos\\modelo_budioes_inception_v2_SGD_0.001-ckpnt.model\\assets\n",
      "Epoch 28/50\n",
      "37/37 [==============================] - 14s 384ms/step - loss: 0.4730 - accuracy: 0.8737 - val_loss: 0.5893 - val_accuracy: 0.8482\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.88393\n",
      "Epoch 29/50\n",
      "37/37 [==============================] - 14s 387ms/step - loss: 0.4794 - accuracy: 0.8737 - val_loss: 0.5367 - val_accuracy: 0.8839\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.88393\n",
      "Epoch 30/50\n",
      "37/37 [==============================] - 16s 419ms/step - loss: 0.4724 - accuracy: 0.8581 - val_loss: 0.5836 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.88393\n",
      "Epoch 31/50\n",
      "37/37 [==============================] - 15s 399ms/step - loss: 0.4627 - accuracy: 0.8772 - val_loss: 0.5412 - val_accuracy: 0.8839\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.88393\n",
      "Epoch 32/50\n",
      "37/37 [==============================] - 14s 377ms/step - loss: 0.4649 - accuracy: 0.8720 - val_loss: 0.5372 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.88393\n",
      "Epoch 33/50\n",
      "37/37 [==============================] - 14s 382ms/step - loss: 0.4382 - accuracy: 0.8858 - val_loss: 0.5316 - val_accuracy: 0.8661\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.88393\n",
      "Epoch 34/50\n",
      "37/37 [==============================] - 14s 370ms/step - loss: 0.4528 - accuracy: 0.8702 - val_loss: 0.5670 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.88393\n",
      "Epoch 35/50\n",
      "37/37 [==============================] - 14s 373ms/step - loss: 0.4446 - accuracy: 0.8789 - val_loss: 0.5031 - val_accuracy: 0.8839\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.88393\n",
      "Epoch 36/50\n",
      "37/37 [==============================] - 14s 383ms/step - loss: 0.4558 - accuracy: 0.8547 - val_loss: 0.5153 - val_accuracy: 0.8661\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.88393\n",
      "Epoch 37/50\n",
      "37/37 [==============================] - 15s 407ms/step - loss: 0.4471 - accuracy: 0.8633 - val_loss: 0.5099 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.88393\n",
      "Epoch 38/50\n",
      "37/37 [==============================] - 16s 435ms/step - loss: 0.4401 - accuracy: 0.8702 - val_loss: 0.5258 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.88393\n",
      "Epoch 39/50\n",
      "37/37 [==============================] - 16s 429ms/step - loss: 0.4262 - accuracy: 0.8858 - val_loss: 0.5132 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.88393\n",
      "Epoch 40/50\n",
      "37/37 [==============================] - 15s 394ms/step - loss: 0.4190 - accuracy: 0.8858 - val_loss: 0.5280 - val_accuracy: 0.8661\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.88393\n",
      "Epoch 41/50\n",
      "37/37 [==============================] - 15s 412ms/step - loss: 0.4166 - accuracy: 0.8945 - val_loss: 0.4936 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.88393\n",
      "Epoch 42/50\n",
      "37/37 [==============================] - 14s 374ms/step - loss: 0.4178 - accuracy: 0.8806 - val_loss: 0.5016 - val_accuracy: 0.8661\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.88393\n",
      "Epoch 43/50\n",
      "37/37 [==============================] - 15s 413ms/step - loss: 0.4003 - accuracy: 0.8841 - val_loss: 0.4950 - val_accuracy: 0.8661\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.88393\n",
      "Epoch 44/50\n",
      "37/37 [==============================] - 15s 394ms/step - loss: 0.4117 - accuracy: 0.8772 - val_loss: 0.4833 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.88393\n",
      "Epoch 45/50\n",
      "37/37 [==============================] - 14s 385ms/step - loss: 0.4035 - accuracy: 0.8875 - val_loss: 0.4853 - val_accuracy: 0.8661\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.88393\n",
      "Epoch 46/50\n",
      "37/37 [==============================] - 14s 389ms/step - loss: 0.4061 - accuracy: 0.8737 - val_loss: 0.4829 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.88393\n",
      "Epoch 47/50\n",
      "37/37 [==============================] - 14s 364ms/step - loss: 0.3862 - accuracy: 0.8858 - val_loss: 0.4703 - val_accuracy: 0.8750\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.88393\n",
      "Epoch 48/50\n",
      "37/37 [==============================] - 14s 363ms/step - loss: 0.3838 - accuracy: 0.9100 - val_loss: 0.4786 - val_accuracy: 0.8839\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.88393\n",
      "Epoch 49/50\n",
      "37/37 [==============================] - 13s 362ms/step - loss: 0.3911 - accuracy: 0.8910 - val_loss: 0.4742 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.88393\n",
      "Epoch 50/50\n",
      "37/37 [==============================] - 13s 360ms/step - loss: 0.3863 - accuracy: 0.8962 - val_loss: 0.4559 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00050: val_accuracy improved from 0.88393 to 0.89286, saving model to C:\\Users\\LDT\\Desktop\\mestrado-unifesp\\exemplos\\modelo_budioes_inception_v2_SGD_0.001-ckpnt.model\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\LDT\\Desktop\\mestrado-unifesp\\exemplos\\modelo_budioes_inception_v2_SGD_0.001-ckpnt.model\\assets\n"
     ]
    }
   ],
   "source": [
    "#fit_generator vai de fato treinar a rede\n",
    "trained_model = model.fit(trainGen, validation_data=valGen,\n",
    "                        steps_per_epoch=get_images(trainFolder)//BATCH_SIZE,\n",
    "                        validation_steps=get_images(valFolder) // BATCH_SIZE,\n",
    "                        epochs = EPOCHS, callbacks=callbacks, verbose =1);\n",
    "#Dividir o número de imagens pelo número de batchs para garantir que cada BATCH seja lido a cada época\n",
    "#tanto no treino (steps_per_epoch) quanto na validação (validation_steps)\n",
    "#verbose = dá output da rede a cada final de época\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1947c248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\LDT\\Desktop\\mestrado-unifesp\\exemplos\\modelo_budioes_inception_v2_SGD_0.001.model\\assets\n"
     ]
    }
   ],
   "source": [
    "#Salva o modelo (pesos + conexões entre os neurônios, ou seja, a estrutura da rede)\n",
    "model.save('C:\\\\Users\\\\LDT\\\\Desktop\\\\mestrado-unifesp\\\\exemplos\\\\modelo_budioes_inception_v2_' + optimizer_name + '_' + str(learning_rate) + \".model\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c0f972b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.learndatasci.com/tutorials/hands-on-transfer-learning-keras/\n",
    "#https://neptune.ai/blog/keras-metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
